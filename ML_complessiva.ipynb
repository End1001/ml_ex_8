{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6a5d8681",
      "metadata": {
        "id": "6a5d8681"
      },
      "source": [
        "# **Machine Learning Project**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d9be223",
      "metadata": {
        "id": "9d9be223"
      },
      "source": [
        "In questa esercitazione metteremo assieme tutte le nozioni apprese dall'inizio del corso per risolvere un task specifico di machine learning."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd9126f8",
      "metadata": {
        "id": "cd9126f8"
      },
      "source": [
        "### **Task: Semi-supervised classification**\n",
        "\n",
        "Il task che vogliamo risolvere è un task di classificazione, caratterizzato però dal fatto che solo una piccola parte dei dati che disponiamo possiede le annotazioni (label). Questa condizione è nota come `Semi-supervised learning`.\n",
        "\n",
        "### **Dataset**\n",
        "\n",
        "Il dataset che utilizzeremo sarà Fashion-MNIST, che contiene immagini di articoli di Zalando, composto da un training set di 60.000 campioni e test set con 10.000 campioni. Ogni campione è in scala di grigi e ha risoluzione 28x28. Il dataset è composto da 10 classi.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c1b2838",
      "metadata": {
        "id": "6c1b2838"
      },
      "source": [
        "## **Pseudo-label**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4726ca22",
      "metadata": {
        "id": "4726ca22"
      },
      "source": [
        "Lo **pseudo-labeling** è una tecnica utilizzata nell'ambito del *semi-supervised learning*. L'idea di base è quella di generare etichette \"artificiali\" (pseudo-etichette) per i dati non etichettati (unlabeled, \"U\"), in modo da utilizzarle durante il training del modello. Per generare queste etichette ci sono diverse strategie: nel contesto di questa esercitazione utilizzeremo un algoritmo di clustering (k-means).\n",
        "\n",
        "Ecco i passaggi generali del processo di pseudo-labeling:\n",
        "\n",
        "1.  **Addestramento Iniziale**: Si addestra un algortimo di clustering sul set non etichettato (U) utilizzando un numero di cluster pari al numero di classi.\n",
        "2.  **Predizione su Dati Etichettati**: Utilizziamo l'algortimo addestrato al punto 1 per clusterizzare i dati etichettati (L), assegnandoli quindi ai cluster che abbiamo trovato durante l' addestramento iniziale.\n",
        "3.  **Mappare i cluster alle etichette**: Creiamo un mapping tra i cluster e le etichette, in modo da capire quale etichetta corrisponde allo specifico cluster. Per fare ciò assegniamo ad ogni cluster la vera label più frequente assegnata a quel cluster, sfruttando la funzione `mode`:\n",
        "\n",
        "```Python\n",
        "from scipy.stats import mode\n",
        "import numpy as np\n",
        "\n",
        "etichette_nel_cluster = np.array([0, 1, 1, 2, 1, 0, 1])\n",
        "\n",
        "risultato_mode = mode(etichette_nel_cluster)\n",
        "\n",
        "print(f\"Oggetto ModeResult: {risultato_mode}\") # Output: ModeResul(mode=1, count=4)\n",
        "print(f\"Etichetta più frequente (moda): {risultato_mode.mode}\") # Output: (moda): 1\n",
        "\n",
        "# etichetta più frequente come singolo numero:\n",
        "etichetta_predominante = risultato_mode.mode\n",
        "print(f\"Etichetta predominante per questo cluster: {etichetta_predominante}\") # Output: 1\n",
        "```\n",
        "\n",
        "4.  **Estrazione pseudo-label**: Alla fine, la classe più presente in un cluster diventa l' etichetta scelta per tutti i campioni assegnati a quel cluster.\n",
        "\n",
        "\n",
        "**Vantaggi**:\n",
        "*   Permette di sfruttare la grande quantità di dati non etichettati, che altrimenti andrebbero sprecati.\n",
        "*   Può migliorare significativamente le prestazioni del modello rispetto all'addestramento con i soli dati etichettati, specialmente quando questi ultimi sono scarsi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "id": "748cbb1a",
      "metadata": {
        "id": "748cbb1a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from scipy.stats import mode # For majority voting\n",
        "from sklearn.neural_network import MLPClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "671e368d",
      "metadata": {
        "id": "671e368d"
      },
      "outputs": [],
      "source": [
        "# Nomi delle classi per Fashion-MNIST\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a7b5d18",
      "metadata": {
        "id": "1a7b5d18"
      },
      "source": [
        "### `load_and_preprocess_data()`\n",
        "\n",
        "In questa funzione dovrete:\n",
        "\n",
        "* Scaricare il dataset.\n",
        "* Riordinare casualmente i dati.\n",
        "* Effettuare reshape.\n",
        "* Scalare i valori dei pixel all' intervallo [0,1].\n",
        "* Ridurre il numero di campioni a 10.000 per il train e 1.000 per il test.\n",
        "\n",
        "La funzione dovrà ritornare nel seguente ordine:\n",
        "\n",
        "1. Il training set ridotto.\n",
        "2. Le etichette di train ridotte.\n",
        "3. Il test set ridotto.\n",
        "4. Le etichette di test ridotte."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "id": "8885ad81",
      "metadata": {
        "id": "8885ad81"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_data():\n",
        "    \"\"\"Carica e pre-processa il dataset Fashion-MNIST.\"\"\"\n",
        "    np.random.seed(0)\n",
        "\n",
        "    # Carica il dataset\n",
        "    (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "    # Riordina casualmente i dati\n",
        "    train_indices = np.random.permutation(len(x_train))\n",
        "    test_indices = np.random.permutation(len(x_test))\n",
        "\n",
        "    x_train = x_train[train_indices]\n",
        "    y_train = y_train[train_indices]\n",
        "    x_test = x_test[test_indices]\n",
        "    y_test = y_test[test_indices]\n",
        "\n",
        "    # Riduci il numero di campioni\n",
        "    x_train = x_train[:10000]\n",
        "    y_train = y_train[:10000]\n",
        "    x_test = x_test[:1000]\n",
        "    y_test = y_test[:1000]\n",
        "\n",
        "    # Reshape e normalizzazione\n",
        "    x_train = x_train.reshape(-1, 28*28) / 255.0\n",
        "    x_test = x_test.reshape(-1, 28*28) / 255.0\n",
        "\n",
        "    print(f\"Shape x_train: {x_train.shape}\")\n",
        "    print(f\"Shape y_train: {y_train.shape}\")\n",
        "    print(f\"Shape x_test: {x_test.shape}\")\n",
        "    print(f\"Shape y_test: {y_test.shape}\")\n",
        "\n",
        "    return x_train, y_train, x_test, y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e4f4f2c",
      "metadata": {
        "id": "7e4f4f2c"
      },
      "source": [
        "### `apply_pca_and_scale`\n",
        "\n",
        "In questa funzione dovrete:\n",
        "\n",
        "* Scalare il training set e il test set.\n",
        "* Applicare PCA con un numero di componenti specificato come parametro della funzione (o, equivalentemente, con una frazione desiderata della varianza espressa).\n",
        "* Stampare il numero di componenti.\n",
        "* Stampare la varianza espressa.\n",
        "\n",
        "La funzione dovrà ritornare nel seguente ordine:\n",
        "\n",
        "1. Il training set trasformato con PCA.\n",
        "2. Il test set trasformato con PCA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "cf661359",
      "metadata": {
        "id": "cf661359"
      },
      "outputs": [],
      "source": [
        "def apply_pca_and_scale(x_train, x_test, n_components):\n",
        "    \"\"\"Applica StandardScaler e PCA.\"\"\"\n",
        "    scaler = StandardScaler()\n",
        "    x_train_scaled = scaler.fit_transform(x_train)\n",
        "    x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "    pca = PCA(n_components=n_components)\n",
        "    x_train_pca = pca.fit_transform(x_train_scaled)\n",
        "    x_test_pca = pca.transform(x_test_scaled)\n",
        "\n",
        "    print(f\"PCA applicata. Numero di componenti selezionate: {pca.n_components_}\")\n",
        "    print(f\"Varianza totale spiegata: {np.sum(pca.explained_variance_ratio_):.4f}\")\n",
        "\n",
        "    print(f\"Shape x_train_pca: {x_train_pca.shape}\")\n",
        "    print(f\"Shape x_test_pca: {x_test_pca.shape}\")\n",
        "\n",
        "    return x_train_pca, x_test_pca"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c19d6064",
      "metadata": {
        "id": "c19d6064"
      },
      "source": [
        "### `create_semi_supervised_split`\n",
        "\n",
        "In questa funzione dovrete:\n",
        "\n",
        "* Splittare il training set in due insiemi, etichettato (L) e non etichettato (U) utilizzando  `train_test_split` con:\n",
        "\n",
        "`test_size`=`(1.0 - labeled_fraction)`\n",
        "\n",
        "* Stampare la shape del set etichettato.\n",
        "* Stampare la shape del set non etichettato.\n",
        "\n",
        "La funzione deve ritornare nell seguente ordine:\n",
        "\n",
        "1. Il set etichettato.\n",
        "2. Le etichette del set etichettato.\n",
        "3. Il set non etichettato.\n",
        "4. Le etichette del set non etichettato. **N.B.** Queste etichette verranno utilizzate **SOLO** per valutare le pseudo-labels, non per l'addestramento.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "id": "8c868c74",
      "metadata": {
        "id": "8c868c74"
      },
      "outputs": [],
      "source": [
        "def create_semi_supervised_split(x_train_pca, y_train, labeled_fraction):\n",
        "    \"\"\"Crea gli insiemi etichettato (L) e non etichettato (U).\"\"\"\n",
        "    x_labeled, x_unlabeled, y_labeled, y_unlabeled = train_test_split(\n",
        "        x_train_pca, y_train, test_size=1.0-labeled_fraction, random_state=42)\n",
        "\n",
        "    print(f\"Dimensione insieme etichettato (L): {len(y_labeled)}\")\n",
        "    print(f\"Dimensione insieme non etichettato (U): {len(y_unlabeled)}\")\n",
        "\n",
        "    return x_labeled, y_labeled, x_unlabeled, y_unlabeled"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4052846d",
      "metadata": {
        "id": "4052846d"
      },
      "source": [
        "### `get_pseudo_labels`\n",
        "\n",
        "In questa funzione dovrete:\n",
        "\n",
        "* Istanziare un algoritmo di clustering (ad esempio, k-means).\n",
        "* Addestrare e predire i clustering sul set non etichettato.\n",
        "* Predire i clustering del set etichettato.\n",
        "* Mappare i cluster ad un etichetta, utilizzando per ogni cluster l'etichetta più presente, estraibile utilizzando la funzione `mode` presentata sopra.\n",
        "* Generare un array `pseudo_labels` assegnando a ogni campione del set non etichettato l'etichetta corrispondente al cluster a cui è stato assegnato.\n",
        "\n",
        "La funzione deve ritornare:\n",
        "\n",
        "1. L' array `pseudo_labels`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "id": "d6560820",
      "metadata": {
        "id": "d6560820"
      },
      "outputs": [],
      "source": [
        "def get_pseudo_labels(x_unlabeled_pca, x_labeled_pca, y_labeled, n_clusters):\n",
        "    # 1. Istanziare algoritmo di clustering\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "\n",
        "    # 2. Allenare il modello di clustering con i dati non etichettati e salvare le assegnazioni ai cluster\n",
        "    cluster_assignments_unlabeled = kmeans.fit_predict(x_unlabeled_pca)\n",
        "\n",
        "    # 3. Calcolare l'assegnamento dei dati etichettati ai cluster\n",
        "    cluster_assignments_labeled = kmeans.predict(x_labeled_pca)\n",
        "\n",
        "    # 4. Mappiamo i cluster alle label vere più frequenti\n",
        "    cluster_to_true_label_map = {}\n",
        "    for k_idx in range(n_clusters):\n",
        "        # 4.1 Troviamo per ogni cluster le etichette vere dei campioni che vi appartengono.\n",
        "        labels_in_cluster = y_labeled[cluster_assignments_labeled == k_idx]\n",
        "\n",
        "        if len(labels_in_cluster) > 0:\n",
        "            # 4.2 Troviamo l'etichetta più frequente per quel cluster.\n",
        "            mode_result = mode(labels_in_cluster)\n",
        "            # Correzione qui: prendiamo solo il primo valore (mode può restituire array)\n",
        "            cluster_to_true_label_map[k_idx] = mode_result.mode[0] if isinstance(mode_result.mode, np.ndarray) else mode_result.mode\n",
        "        else:\n",
        "            print(f\"Attenzione: Cluster {k_idx} non ha campioni etichettati per il mapping. Assegno NaN.\")\n",
        "            cluster_to_true_label_map[k_idx] = np.nan\n",
        "\n",
        "    pseudo_labels_list = []\n",
        "\n",
        "    for c_assign in cluster_assignments_unlabeled:\n",
        "        if c_assign in cluster_to_true_label_map:\n",
        "            pseudo_labels_list.append(cluster_to_true_label_map[c_assign])\n",
        "        else:\n",
        "            # Se il cluster non ha una mappatura, possiamo assegnare un'etichetta di default o ignorarlo\n",
        "            pseudo_labels_list.append(np.nan)\n",
        "\n",
        "    # 5. Convertiamo la lista in un array numpy\n",
        "    pseudo_labels = np.array(pseudo_labels_list)\n",
        "    print(pseudo_labels.shape)\n",
        "\n",
        "    return pseudo_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "316409a5",
      "metadata": {
        "id": "316409a5"
      },
      "source": [
        "### `train_and_evaluate_classifier`\n",
        "\n",
        "In questa funzione dovrete:\n",
        "\n",
        "* Rimuovere eventuali campioni con etichette NaN (potrebbero provenire da pseudo labels non mappate).\n",
        "* Istanziare il modello utilizzando `model_class` come oggetto e `classifier_args` come argomenti. Esempio:\n",
        "\n",
        "```Python\n",
        "model_class = MLPClassifier\n",
        "classifier_args = {'max_iter': 200, 'hidden_layer_sizes': (100, 50)}\n",
        "model = model_class(**classifier_args)\n",
        "\n",
        "# Equivalente a:\n",
        "model = MLPClassifier(max_iter=200, hidden_layer_sizes=(100, 50))\n",
        "\n",
        "```\n",
        "\n",
        "* Allenare il modello sul training set a cui sono stati rimossi i campioni con etichette NaN.\n",
        "* Calcolare l' accuracy.\n",
        "* Stampare il `title`, che consiste nel titolo dell' esperimento eseguito. Questo perchè tale funzione verrà riutilizzata diverse volte per più set di dati. Un titolo ci permetterà di identificare quali risultati stiamo producendo.\n",
        "* Stampare l' accuracy.\n",
        "* Stampare il classification report.\n",
        "\n",
        "La funzione deve ritornare:\n",
        "\n",
        "1. Il modello.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "id": "d4d5b673",
      "metadata": {
        "id": "d4d5b673"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate_classifier(model_class, classifier_args, x_train, y_train, x_test, y_test, title, class_names_list):\n",
        "    valid_indices_train = ~np.isnan(y_train)\n",
        "    x_train_filtered = x_train[valid_indices_train]\n",
        "    y_train_filtered = y_train[valid_indices_train]\n",
        "\n",
        "    model = model_class(**classifier_args)\n",
        "    model.fit(x_train_filtered, y_train_filtered)\n",
        "\n",
        "    y_pred = model.predict(x_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\n{title}\")\n",
        "    print(f\"Accuratezza su test set: {accuracy:.4f}\")\n",
        "    print(classification_report(y_test, y_pred, target_names=class_names_list))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a1c37dd",
      "metadata": {
        "id": "3a1c37dd"
      },
      "source": [
        "### `main`\n",
        "\n",
        "In questa funzione dovrete:\n",
        "\n",
        "* Utilizzare la funzione `load_and_preprocess_data` per caricare e pre-processare i dati.\n",
        "* Utilizzare la funzione `apply_pca_and_scale` per applicare scaling e PCA.\n",
        "* Utilizzare la funzione `create_semi_supervised_split` per dividere il train set in set etichettato e non etichettato.\n",
        "* Utilizzare la funzione `get_pseudo_labels` per calcoalre le pseudo labels sul set non etichettato.\n",
        "* Calcolare l' accuracy delle pseudo labels, cioè confrontarle con quelle vere in modo da vedere quanto sono accurate.\n",
        "* Utilizzare la funzione `train_and_evaluate_classifier` per allenare e valutare il modello solo sui dati etichettati (L).\n",
        "* Utilizzare la funzione `train_and_evaluate_classifier` per allenare e valutare il modello solo sui dati non etichettati (U).\n",
        "* Utilizzare la funzione `train_and_evaluate_classifier` per allenare e valutare il modello sui dati etichettati (L) più quelli non etichettati (U).\n",
        "* Utilizzare la funzione `train_and_evaluate_classifier` per allenare e valutare il modello su tutto il dataset originale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "id": "715e5f56",
      "metadata": {
        "id": "715e5f56"
      },
      "outputs": [],
      "source": [
        "def main(classifier_class, classifier_args, n_components_pca, labeled_fraction, n_clusters):\n",
        "    # 1. Carica e pre-processa i dati\n",
        "    try:\n",
        "        x_train, y_train, x_test, y_test = load_and_preprocess_data()\n",
        "        print(f\"Dimensioni training set: {x_train.shape}, {y_train.shape}\")\n",
        "        print(f\"Dimensioni test set: {x_test.shape}, {y_test.shape}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Errore nel caricamento dati: {str(e)}\")\n",
        "        return\n",
        "\n",
        "    # 2. Applica PCA e scaling\n",
        "    try:\n",
        "        x_train_pca, x_test_pca = apply_pca_and_scale(x_train, x_test, n_components_pca)\n",
        "    except Exception as e:\n",
        "        print(f\"Errore in PCA: {str(e)}\")\n",
        "        return\n",
        "\n",
        "    # 3. Crea split semi-supervised\n",
        "    try:\n",
        "        x_labeled_pca, y_labeled, x_unlabeled_pca, y_unlabeled = create_semi_supervised_split(\n",
        "            x_train_pca, y_train, labeled_fraction)\n",
        "    except Exception as e:\n",
        "        print(f\"Errore nella creazione dello split: {str(e)}\")\n",
        "        return\n",
        "\n",
        "    # 4. Ottieni pseudo-labels\n",
        "    try:\n",
        "        pseudo_labels = get_pseudo_labels(x_unlabeled_pca, x_labeled_pca, y_labeled, n_clusters)\n",
        "\n",
        "        # Calcola accuratezza pseudo-labels solo su campioni validi\n",
        "        valid_pseudo_indices = ~np.isnan(pseudo_labels)\n",
        "        if sum(valid_pseudo_indices) > 0:  # Verifica che ci siano campioni validi\n",
        "            pseudo_accuracy = accuracy_score(y_unlabeled[valid_pseudo_indices],\n",
        "                                          pseudo_labels[valid_pseudo_indices])\n",
        "            print(f\"\\nAccuratezza delle pseudo-etichette (sui campioni mappabili di U): {pseudo_accuracy:.4f}\")\n",
        "        else:\n",
        "            print(\"\\nNessuna pseudo-label valida generata!\")\n",
        "            return\n",
        "    except Exception as e:\n",
        "        print(f\"Errore nella generazione pseudo-labels: {str(e)}\")\n",
        "        return\n",
        "\n",
        "    # 5. Valutazione modelli\n",
        "    try:\n",
        "        # 5.1 Baseline - Solo dati etichettati (L)\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        model_l = train_and_evaluate_classifier(\n",
        "            classifier_class, classifier_args,\n",
        "            x_labeled_pca, y_labeled,\n",
        "            x_test_pca, y_test,\n",
        "            \"Baseline - Solo dati etichettati (L)\",\n",
        "            class_names\n",
        "        )\n",
        "\n",
        "        # 5.2 Solo dati con pseudo-etichette (U_pseudo)\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        model_u = train_and_evaluate_classifier(\n",
        "            classifier_class, classifier_args,\n",
        "            x_unlabeled_pca, pseudo_labels,\n",
        "            x_test_pca, y_test,\n",
        "            \"Solo dati con pseudo-etichette (U_pseudo)\",\n",
        "            class_names\n",
        "        )\n",
        "\n",
        "        # 5.3 Combinato - Dati etichettati (L) + Pseudo-etichette (U_pseudo)\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        x_combined = np.concatenate([x_labeled_pca, x_unlabeled_pca[valid_pseudo_indices]])\n",
        "        y_combined = np.concatenate([y_labeled, pseudo_labels[valid_pseudo_indices]])\n",
        "\n",
        "        model_combined = train_and_evaluate_classifier(\n",
        "            classifier_class, classifier_args,\n",
        "            x_combined, y_combined,\n",
        "            x_test_pca, y_test,\n",
        "            \"Combinato - Dati etichettati (L) + Pseudo-etichette (U_pseudo)\",\n",
        "            class_names\n",
        "        )\n",
        "\n",
        "        # 5.4 Oracle - Supervisione completa (intero training set)\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        model_oracle = train_and_evaluate_classifier(\n",
        "            classifier_class, classifier_args,\n",
        "            x_train_pca, y_train,\n",
        "            x_test_pca, y_test,\n",
        "            \"Oracle - Supervisione completa (intero training set)\",\n",
        "            class_names\n",
        "        )\n",
        "\n",
        "        return model_l, model_u, model_combined, model_oracle\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Errore nell'addestramento modelli: {str(e)}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59e4e39c",
      "metadata": {
        "id": "59e4e39c"
      },
      "source": [
        "### **Utilizzare la funzione `main`**\n",
        "\n",
        "Specifichiamo adesso un set di parametri richiesti dalla funzione main e utilizziamola. Nello specifico la funzione main ha bisogno di:\n",
        "\n",
        "* `classifier_class`: quale classificatore utilizzare, ad esempio `'MLPClassifier'`, `'LogisticRegression'` o altri visti in precedenza.\n",
        "* `classifier_args`: un dizionario contenente i parametri del classificatore scelto, ad esempio un `MLPClassifier` necessiterà del parametro `hidden_layer_sizes`. Dipendentemente da quale classificatore scegliete dovrete creare il dizionario.\n",
        "* `n_components_pca`: numero di componenti di PCA che vogliamo utilizzare. Se specifichiamo un valore compreso in [0, 1] questo verrà considerato come la percentuale di varianza che vogliamo mentenere.\n",
        "* `labeled_fraction`: percentuale di dati da usare come insieme etichettato. Si consiglia il valore 0.002 corrispondente allo 0.2%, cioè 16 immagini su 8000.\n",
        "* `n_clusters`: numero di cluster da utilizzare, nel nostro caso vogliamo che ci sia un cluster per ogni classe, quindi 10.\n",
        "\n",
        "Infine utilizziamo la funzione main."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "id": "beadf602",
      "metadata": {
        "id": "beadf602"
      },
      "outputs": [],
      "source": [
        "# Parametri\n",
        "CLASSIFIER_CLASS = MLPClassifier  # Modello da usare, ad esempio LogisticRegression o SVC\n",
        "CLASSIFIER_ARGS = {\n",
        "    'max_iter': 20,\n",
        "    'hidden_layer_sizes': (200,200)  # Aumenta il numero di iterazioni per la convergenza\n",
        "}\n",
        "N_COMPONENTS_PCA = 0.95  # Mantiene il 95% della varianza spiegata, o un numero fisso es. 50\n",
        "LABELED_FRACTION = 0.002   # Frazione di dati da usare come insieme etichettato L\n",
        "N_CLUSTERS = 10          # Fashion-MNIST ha 10 classi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "id": "d9d2cb39",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9d2cb39",
        "outputId": "a729dd03-dc14-4b3a-f554-00da28c1894a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape x_train: (10000, 784)\n",
            "Shape y_train: (10000,)\n",
            "Shape x_test: (1000, 784)\n",
            "Shape y_test: (1000,)\n",
            "Dimensioni training set: (10000, 784), (10000,)\n",
            "Dimensioni test set: (1000, 784), (1000,)\n",
            "PCA applicata. Numero di componenti selezionate: 245\n",
            "Varianza totale spiegata: 0.9502\n",
            "Shape x_train_pca: (10000, 245)\n",
            "Shape x_test_pca: (1000, 245)\n",
            "Dimensione insieme etichettato (L): 20\n",
            "Dimensione insieme non etichettato (U): 9980\n",
            "(9980,)\n",
            "\n",
            "Accuratezza delle pseudo-etichette (sui campioni mappabili di U): 0.4379\n",
            "\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Baseline - Solo dati etichettati (L)\n",
            "Accuratezza su test set: 0.4350\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " T-shirt/top       0.61      0.40      0.48        85\n",
            "     Trouser       0.97      0.37      0.54        91\n",
            "    Pullover       0.55      0.15      0.23       109\n",
            "       Dress       0.43      0.79      0.56       102\n",
            "        Coat       0.40      0.71      0.52       112\n",
            "      Sandal       0.25      0.91      0.40       104\n",
            "       Shirt       0.33      0.03      0.06        95\n",
            "     Sneaker       0.86      0.19      0.31       101\n",
            "         Bag       0.93      0.12      0.22       113\n",
            "  Ankle boot       0.78      0.67      0.72        88\n",
            "\n",
            "    accuracy                           0.43      1000\n",
            "   macro avg       0.61      0.44      0.40      1000\n",
            "weighted avg       0.61      0.43      0.40      1000\n",
            "\n",
            "\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Solo dati con pseudo-etichette (U_pseudo)\n",
            "Accuratezza su test set: 0.4070\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " T-shirt/top       0.35      0.38      0.36        85\n",
            "     Trouser       0.66      0.87      0.75        91\n",
            "    Pullover       0.00      0.00      0.00       109\n",
            "       Dress       0.39      0.46      0.42       102\n",
            "        Coat       0.43      0.58      0.49       112\n",
            "      Sandal       0.29      0.84      0.43       104\n",
            "       Shirt       0.14      0.15      0.14        95\n",
            "     Sneaker       0.00      0.00      0.00       101\n",
            "         Bag       0.00      0.00      0.00       113\n",
            "  Ankle boot       0.72      0.94      0.82        88\n",
            "\n",
            "    accuracy                           0.41      1000\n",
            "   macro avg       0.30      0.42      0.34      1000\n",
            "weighted avg       0.28      0.41      0.33      1000\n",
            "\n",
            "\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Combinato - Dati etichettati (L) + Pseudo-etichette (U_pseudo)\n",
            "Accuratezza su test set: 0.4020\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " T-shirt/top       0.36      0.39      0.37        85\n",
            "     Trouser       0.65      0.87      0.75        91\n",
            "    Pullover       0.00      0.00      0.00       109\n",
            "       Dress       0.36      0.44      0.40       102\n",
            "        Coat       0.43      0.56      0.49       112\n",
            "      Sandal       0.29      0.84      0.43       104\n",
            "       Shirt       0.13      0.14      0.13        95\n",
            "     Sneaker       0.00      0.00      0.00       101\n",
            "         Bag       0.00      0.00      0.00       113\n",
            "  Ankle boot       0.72      0.93      0.81        88\n",
            "\n",
            "    accuracy                           0.40      1000\n",
            "   macro avg       0.29      0.42      0.34      1000\n",
            "weighted avg       0.28      0.40      0.32      1000\n",
            "\n",
            "\n",
            "==================================================\n",
            "\n",
            "Oracle - Supervisione completa (intero training set)\n",
            "Accuratezza su test set: 0.8570\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " T-shirt/top       0.80      0.74      0.77        85\n",
            "     Trouser       0.99      0.96      0.97        91\n",
            "    Pullover       0.77      0.81      0.79       109\n",
            "       Dress       0.77      0.90      0.83       102\n",
            "        Coat       0.78      0.78      0.78       112\n",
            "      Sandal       0.97      0.95      0.96       104\n",
            "       Shirt       0.65      0.56      0.60        95\n",
            "     Sneaker       0.95      0.93      0.94       101\n",
            "         Bag       0.97      0.98      0.98       113\n",
            "  Ankle boot       0.90      0.94      0.92        88\n",
            "\n",
            "    accuracy                           0.86      1000\n",
            "   macro avg       0.86      0.85      0.85      1000\n",
            "weighted avg       0.86      0.86      0.86      1000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(MLPClassifier(hidden_layer_sizes=(200, 200), max_iter=20),\n",
              " MLPClassifier(hidden_layer_sizes=(200, 200), max_iter=20),\n",
              " MLPClassifier(hidden_layer_sizes=(200, 200), max_iter=20),\n",
              " MLPClassifier(hidden_layer_sizes=(200, 200), max_iter=20))"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ],
      "source": [
        "main(\n",
        "    CLASSIFIER_CLASS,\n",
        "    CLASSIFIER_ARGS,\n",
        "    N_COMPONENTS_PCA,\n",
        "    LABELED_FRACTION,\n",
        "    N_CLUSTERS\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "main",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}